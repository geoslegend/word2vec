{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Word Vectors with TensorFlow:  Hyperparameter Tuning\n",
    "Patrick Coady (pcoady@alum.mit.edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from wordvector import WordVector\n",
    "from windowmodel import WindowModel\n",
    "from plot_util import plot_results\n",
    "import docload\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = ['../data/adventures_of_sherlock_holmes.txt',\n",
    "        '../data/hound_of_the_baskervilles.txt',\n",
    "        '../data/sign_of_the_four.txt']\n",
    "word_array, dictionary, num_lines, num_words = docload.build_word_array(\n",
    "    files, vocab_size=50000, gutenberg=True)\n",
    "print('Document loaded and processed: {} lines, {} words.'\n",
    "      .format(num_lines, num_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Sizes: Embedding Layer and Hidden Layer\n",
    "\n",
    "embed_size = {32, 64, 128}  \n",
    "hid_size = {32, 64, 128}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x, y = WindowModel.build_training_set(word_array)\n",
    "\n",
    "# shuffle and split 10% validation data\n",
    "x_shuf, y_shuf = sklearn.utils.shuffle(x, y, random_state=0)\n",
    "split = round(x_shuf.shape[0]*0.9)\n",
    "x_val, y_val = (x_shuf[split:, :], y_shuf[split:, :])\n",
    "x_train, y_train = (x[:split, :], y[:split, :])\n",
    "results_list = []\n",
    "\n",
    "count = 0\n",
    "for embed_size in [32, 64, 128]:\n",
    "    for hid_size in [32, 64, 128]:\n",
    "        print('{}) embed size = {}, hid_size = {}'.format(count,embed_size, hid_size))\n",
    "        count += 1\n",
    "        graph_params = {'batch_size': 32,\n",
    "                        'vocab_size': np.max(x)+1,\n",
    "                        'embed_size': embed_size,\n",
    "                        'hid_size': hid_size,\n",
    "                        'neg_samples': 64,\n",
    "                        'learn_rate': 0.002,\n",
    "                        'optimizer': 'RMSProp'}\n",
    "        model = WindowModel(graph_params)\n",
    "        results = model.train(x_train, y_train, x_val, y_val, epochs=80, verbose=False)\n",
    "        results_list.append((graph_params, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_results(results_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate\n",
    "Try combinations of:\n",
    "- learn_rate = {0.0003, 0.001, 0.003, 0.01, 0.02}\n",
    "- embed_size = hid_size = {64, 128}\n",
    "\n",
    "*Note 1: batch_size of 64 was found to be worse than 32.*  \n",
    "*Note 2: noticed high run-to-run variation even with no parameter changes: I had mistakenly iterated through learning rates, but didn't actually assign them to the model parameters.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_list2 = []\n",
    "\n",
    "count = 0\n",
    "for learn_rate in [0.0003, 0.001, 0.003, 0.01, 0.03]:\n",
    "    for he_size in [64, 128]:\n",
    "        print('{}) learn_rate = {}, hid_size = embed_size = {}'\n",
    "              .format(count, learn_rate, he_size))\n",
    "        count += 1\n",
    "        graph_params = {'batch_size': 32,\n",
    "                        'vocab_size': np.max(x)+1,\n",
    "                        'embed_size': he_size,\n",
    "                        'hid_size': he_size,\n",
    "                        'neg_samples': 64,\n",
    "                        'learn_rate': learn_rate,\n",
    "                        'optimizer': 'RMSProp'} \n",
    "        model = WindowModel(graph_params)\n",
    "        results = model.train(x_train, y_train, x_val, y_val, epochs=120, verbose=False)\n",
    "        results_list2.append((graph_params, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_results(results_list2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
